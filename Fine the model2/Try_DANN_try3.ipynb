{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D, BatchNormalization, Dropout, Layer, LSTM, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhw_merge = pd.read_csv('dhw_merge.csv')\n",
    "elec_merge  = pd.read_csv('elec_merge.csv')\n",
    "n_elec_merge = pd.read_csv('n_elec_merge.csv')\n",
    "\n",
    "dhw_merge = dhw_merge.drop(['YEAR'], axis=1)\n",
    "elec_merge = elec_merge.drop(['YEAR'], axis=1)\n",
    "n_elec_merge = n_elec_merge.drop(['YEAR'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  For Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhw_X = dhw_merge.drop(['DHW'], axis=1)\n",
    "dhw_Y = dhw_merge[['DHW']]\n",
    "\n",
    "scaler_dhw = MinMaxScaler()\n",
    "scaler_dhw.fit(dhw_X)\n",
    "scaled_dhw_X = scaler_dhw.transform(dhw_X)\n",
    "\n",
    "new_dhw_X = pd.DataFrame(scaled_dhw_X, index=dhw_X.index, columns=dhw_X.columns)\n",
    "new_dhw = pd.concat([new_dhw_X, dhw_Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_X = elec_merge.drop(['ELEC'], axis=1)\n",
    "elec_Y = elec_merge[['ELEC']]\n",
    "\n",
    "scaler_elec = MinMaxScaler()\n",
    "scaler_elec.fit(elec_X)\n",
    "scaled_elec_X = scaler_elec.transform(elec_X)\n",
    "\n",
    "new_elec_X = pd.DataFrame(scaled_elec_X, index=elec_X.index, columns=elec_X.columns)\n",
    "new_elec = pd.concat([new_elec_X, elec_Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elec_X = n_elec_merge.drop(['n_elec'], axis=1)\n",
    "n_elec_Y = n_elec_merge[['n_elec']]\n",
    "\n",
    "scaler_n_elec = MinMaxScaler()\n",
    "scaler_n_elec.fit(n_elec_X)\n",
    "scaled_n_elec_X = scaler_n_elec.transform(n_elec_X)\n",
    "\n",
    "new_n_elec_X = pd.DataFrame(scaled_n_elec_X, index=n_elec_X.index, columns=n_elec_X.columns)\n",
    "new_n_elec = pd.concat([new_n_elec_X, n_elec_Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dhw = new_dhw.iloc[:-1,]\n",
    "target_dhw = new_dhw[['DHW']].iloc[1:]\n",
    "\n",
    "trainX_dhw, testX_dhw, trainY_dhw, testY_dhw = train_test_split(input_dhw,target_dhw,test_size=0.3,shuffle=False,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_elec = new_elec.iloc[:-1,]\n",
    "target_elec = new_elec[['ELEC']].iloc[1:]\n",
    "\n",
    "trainX_elec, testX_elec, trainY_elec, testY_elec = train_test_split(input_elec,target_elec,test_size=0.3,shuffle=False,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = new_n_elec.iloc[:-1,]\n",
    "target = new_n_elec[['n_elec']].iloc[1:]\n",
    "\n",
    "trainX_n_elec, testX_n_elec, trainY_n_elec, testY_n_elec = train_test_split(input,target,test_size=0.3,shuffle=False,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(input, target, seqLength):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for i in range(len(input) - seqLength):\n",
    "        tx = input.iloc[i:i+seqLength]\n",
    "        ty = target.iloc[i+seqLength-1]\n",
    "        xdata.append(tx)\n",
    "        ydata.append(ty)\n",
    "    return np.array(xdata), np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_n_elec2 = trainX_n_elec.iloc[:trainX_elec.shape[0], :]\n",
    "testX_n_elec2 = testX_n_elec.iloc[:testX_elec.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx_dhw, trainy_dhw = buildDataSet(trainX_dhw, trainY_dhw, 3)\n",
    "#testx_dhw, testy_dhw = buildDataSet(testX_dhw, testY_dhw, 3)\n",
    "trainx_elec, trainy_elec = buildDataSet(trainX_elec, trainY_elec, 3)\n",
    "testx_elec, testy_elec = buildDataSet(testX_elec, testY_elec, 3)\n",
    "trainx_n_elec, trainy_n_elec = buildDataSet(trainX_n_elec2, trainY_n_elec, 3)\n",
    "testx_n_elec, testy_n_elec = buildDataSet(testX_n_elec2, testY_n_elec, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2988, 3, 12)\n",
      "(2988, 1)\n",
      "(2988, 3, 12)\n",
      "(2988, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainx_n_elec.shape)\n",
    "print(trainy_n_elec.shape)\n",
    "print(trainx_elec.shape)\n",
    "print(trainy_elec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_n_elec = trainx_n_elec.reshape((trainx_n_elec.shape[0], trainx_n_elec.shape[1], trainx_n_elec.shape[2], 1))\n",
    "testx_n_elec = testx_n_elec.reshape((testx_n_elec.shape[0], testx_n_elec.shape[1], testx_n_elec.shape[2], 1))\n",
    "trainx_elec = trainx_elec.reshape((trainx_elec.shape[0], trainx_elec.shape[1], trainx_elec.shape[2], 1))\n",
    "testx_elec = testx_elec.reshape((testx_elec.shape[0], testx_elec.shape[1], testx_elec.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2988, 3, 12, 1)\n",
      "(2988, 1)\n",
      "(2988, 3, 12, 1)\n",
      "(2988, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainx_n_elec.shape)\n",
    "print(trainy_n_elec.shape)\n",
    "print(trainx_elec.shape)\n",
    "print(trainy_elec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Datasets\n",
    "BATCH_SIZE = 512\n",
    "source_dataset = tf.data.Dataset.from_tensor_slices((trainx_n_elec, trainy_n_elec)).batch(BATCH_SIZE*2)\n",
    "da_dataset = tf.data.Dataset.from_tensor_slices((trainx_n_elec, trainy_n_elec, trainx_elec, trainy_elec)).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((testx_elec, testy_elec)).batch(BATCH_SIZE*2) #Test Dataset over Target Domain\n",
    "test_dataset2 = tf.data.Dataset.from_tensor_slices((trainx_elec, trainy_elec)).batch(BATCH_SIZE*2) #Test Dataset over Target (used for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def gradient_reverse(x, lamda=1.0):\n",
    "    y = tf.identity(x)\n",
    "    \n",
    "    def grad(dy):\n",
    "        return lamda * -dy, None\n",
    "    \n",
    "    return y, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(selx, x, lamda=1.0):\n",
    "        return gradient_reverse(x, lamda)\n",
    "    \n",
    "class DANN(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature Extractor\n",
    "        self.feature_extractor_layer0 = LSTM(64, activation='swish', return_sequences=True),\n",
    "        self.feature_extractor_layer1 = LSTM(64, activation='swish', return_sequences=False)\n",
    "        \n",
    "        # Label Predictor\n",
    "        self.label_predcitor_layer0 = Dense(64, activation='relu')\n",
    "        self.label_predcitor_layer1 = Dense(1, activation='relu')\n",
    "        \n",
    "        # Domain Predictor\n",
    "        self.domain_predictor_layer0 = GradientReversalLayer()\n",
    "        self.domain_predictor_layer1 = Dense(64, activation='relu')\n",
    "        self.domain_predictor_layer2 = Dense(1, activation=None)\n",
    "        \n",
    "    def call(self, x ,train=False, source_train=True, lamda=1.0):\n",
    "        # Featrue Extractor\n",
    "        x = self.feature_extractor_layer0(x)\n",
    "        x = self.feature_extractor_layer1(x)\n",
    "        \n",
    "        feature = tf.reshape(x, [-1 * 4 * 4 * 64])\n",
    "        \n",
    "        # Label Predictor\n",
    "        if source_train is True:\n",
    "            feature_slice = feature\n",
    "        else:\n",
    "            feature_slice = tf.slice(feature, [0, 0], [feature.shape[0] // 2, -1])\n",
    "            \n",
    "        lp_x = self.label_predcitor_layer0(feature_slice)\n",
    "        l_logits = self.label_predcitor_layer1(lp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
